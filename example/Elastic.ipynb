{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "793f0fb9-3778-49fb-a4ba-fbccdcc842ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "from ase import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77cbf1ac-c254-4a0d-8190-6bdf4b908855",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C3S_CellOPT.out'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     22\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC3S_CellOPT.out\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# 替换成你实际文件的路径\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m last_stress_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mextract_last_stress_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m last_stress_tensor\n",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m, in \u001b[0;36mextract_last_stress_tensor\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mextract_last_stress_tensor\u001b[39m(file_path):\n\u001b[1;32m      3\u001b[0m     stress_tensors \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      6\u001b[0m         lines \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;66;03m# 遍历文件中的每一行\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/CP2K/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C3S_CellOPT.out'"
     ]
    }
   ],
   "source": [
    "def extract_last_stress_tensor(file_path):\n",
    "    \n",
    "    stress_tensors = []\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "        # 遍历文件中的每一行\n",
    "        for i, line in enumerate(lines):\n",
    "            if 'STRESS| Analytical stress tensor [GPa]' in line:\n",
    "                # 找到 STRESS| Analytical stress tensor 的位置，开始解析应力矩阵\n",
    "                stress_matrix = []\n",
    "                for j in range(i + 2, i + 5):  # 取接下来的 3 行应力张量\n",
    "                    row_data = lines[j].split()[2:]  # 取 x, y, z 列的值\n",
    "                    stress_matrix.append([np.round(float(val), 11) for val in row_data])\n",
    "                stress_tensors.append(np.array(stress_matrix))  # 将该矩阵加入到列表中\n",
    "    if stress_tensors:\n",
    "        return stress_tensors[-1]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "file_path = 'C3S_CellOPT.out'  # 替换成你实际文件的路径\n",
    "last_stress_tensor = extract_last_stress_tensor(file_path)\n",
    "last_stress_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1545df0a-40f9-4528-8dba-4604af65dd1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.22320878e+01,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 1.00506000e-05,  1.41445700e+01,  0.00000000e+00],\n",
       "       [-8.12799176e+00, -2.44980000e-06,  1.69863453e+01]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_last_frame_cell_vectors(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = [line for line in file.readlines() if line.strip()]\n",
    "\n",
    "    last_frame_line = content[-1]\n",
    "    parts = last_frame_line.split()\n",
    "\n",
    "    vector_a = [np.round(float(parts[2]), 10), np.round(float(parts[3]), 10), np.round(float(parts[4]), 10)]\n",
    "    vector_b = [np.round(float(parts[5]), 10), np.round(float(parts[6]), 10), np.round(float(parts[7]), 10)]\n",
    "    vector_c = [np.round(float(parts[8]), 10), np.round(float(parts[9]), 10), np.round(float(parts[10]), 10)]\n",
    "\n",
    "    cell_vectors = np.array([vector_a, vector_b, vector_c])\n",
    "    return cell_vectors\n",
    "file_path = './C3S_CellOPT-1.cell'\n",
    "last_frame_cell_vectors = read_last_frame_cell_vectors(file_path)\n",
    "last_frame_cell_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d14308c1-2852-4d5c-81ad-1e494e87af77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_last_frame(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        file_content = file.readlines()\n",
    "\n",
    "    frame_start_index = None\n",
    "    for i in range(len(file_content) - 1, -1, -1):\n",
    "        if file_content[i].startswith(\" i =\"):\n",
    "            frame_start_index = i\n",
    "            break\n",
    "\n",
    "    atoms_in_last_frame = file_content[frame_start_index + 1:]\n",
    "\n",
    "    frame_end_index = None\n",
    "    for i in range(len(atoms_in_last_frame)):\n",
    "        if atoms_in_last_frame[i].startswith(\" i =\"):\n",
    "            frame_end_index = i\n",
    "            break\n",
    "            \n",
    "    if frame_end_index is not None:\n",
    "        atoms_in_last_frame = atoms_in_last_frame[:frame_end_index]\n",
    "\n",
    "    atom_data = []\n",
    "    for line in atoms_in_last_frame:\n",
    "        atom_info = line.split()\n",
    "        atom_name = atom_info[0]\n",
    "        coordinates = [float(coord) for coord in atom_info[1:]]\n",
    "        atom_data.append((atom_name, coordinates))\n",
    "    return atom_data\n",
    "\n",
    "\n",
    "def save_xyz_file(atom_data, output_path):\n",
    "    num_atoms = len(atom_data)\n",
    "    with open(output_path, 'w') as file:\n",
    "        file.write(f\"{num_atoms}\\n\")\n",
    "        file.write(\"Lattice\\n\")\n",
    "        \n",
    "        for atom in atom_data:\n",
    "            atom_name = atom[0]\n",
    "            coordinates = atom[1]\n",
    "            formatted_coords = \" \".join([f\"{coord:.10f}\" for coord in coordinates])\n",
    "            file.write(f\"{atom_name} {formatted_coords}\\n\")\n",
    "\n",
    "\n",
    "file_path = './C3S_CellOPT-pos-1.xyz'\n",
    "last_frame_atoms = extract_last_frame(file_path)\n",
    "\n",
    "output_path = './coord.xyz'\n",
    "save_xyz_file(last_frame_atoms, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "453ef630-27c1-46fd-a2f5-8bd5b28b6a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./epsilonxx',\n",
       " './epsilonyy',\n",
       " './epsilonzz',\n",
       " './epsilonxy',\n",
       " './epsilonyz',\n",
       " './epsilonzx']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "# 创建所需的文件夹结构\n",
    "def create_folders(base_folders):\n",
    "    for base_folder in base_folders:\n",
    "        pos_folder = os.path.join(base_folder, \"pos\")\n",
    "        neg_folder = os.path.join(base_folder, \"neg\")\n",
    "        \n",
    "        # 如果文件夹存在，清空其中内容\n",
    "        if os.path.exists(base_folder):\n",
    "            shutil.rmtree(base_folder)\n",
    "        \n",
    "        # 创建文件夹结构\n",
    "        os.makedirs(pos_folder, exist_ok=True)\n",
    "        os.makedirs(neg_folder, exist_ok=True)\n",
    "\n",
    "# 读取并修改 CP2K 输入文件\n",
    "def modify_cp2k_input(input_file_path, output_file_path, cell_vectors):\n",
    "    with open(input_file_path, 'r') as file:\n",
    "        input_lines = file.readlines()\n",
    "\n",
    "    # 标志位，判断是否进入&CELL部分\n",
    "    in_cell_section = False\n",
    "    new_lines = []\n",
    "\n",
    "    # 记录&CELL部分的缩进\n",
    "    cell_indent = None\n",
    "\n",
    "    for line in input_lines:\n",
    "        # 检查是否进入&CELL部分\n",
    "        if \"&CELL\" in line:\n",
    "            in_cell_section = True\n",
    "            cell_indent = len(line) - len(line.lstrip())  # 获取&CELL行的前导空格数\n",
    "            new_lines.append(line)  # 保留原有的&CELL部分头\n",
    "            continue\n",
    "\n",
    "        # 如果进入了&CELL部分，并且当前行是A、B、C基础矢量行，进行修改\n",
    "        if in_cell_section:\n",
    "            if \"&END CELL\" in line:\n",
    "                in_cell_section = False\n",
    "                new_lines.append(line)\n",
    "            else:\n",
    "                # 忽略每行前的空格，检查是否是A、B、C行\n",
    "                stripped_line = line.strip()\n",
    "                if stripped_line.startswith(\"A\"):\n",
    "                    new_lines.append(f\"{' ' * (cell_indent + 2)}A  {cell_vectors[0,0]:.10f} {cell_vectors[0,1]:.10f} {cell_vectors[0,2]:.10f}\\n\")\n",
    "                elif stripped_line.startswith(\"B\"):\n",
    "                    new_lines.append(f\"{' ' * (cell_indent + 2)}B  {cell_vectors[1,0]:.10f} {cell_vectors[1,1]:.10f} {cell_vectors[1,2]:.10f}\\n\")\n",
    "                elif stripped_line.startswith(\"C\"):\n",
    "                    new_lines.append(f\"{' ' * (cell_indent + 2)}C  {cell_vectors[2,0]:.10f} {cell_vectors[2,1]:.10f} {cell_vectors[2,2]:.10f}\\n\")\n",
    "                else:\n",
    "                    new_lines.append(line)\n",
    "        else:\n",
    "            new_lines.append(line)\n",
    "\n",
    "    # 将修改后的内容写入到新的输入文件\n",
    "    with open(output_file_path, 'w') as output_file:\n",
    "        output_file.writelines(new_lines)\n",
    "\n",
    "# 示例输入：假设 last_frame_cell_vectors 是从最后一帧中提取的基础矢量\n",
    "last_frame_cell_vectors = np.array([\n",
    "    [10.0, 0.0, 0.0],\n",
    "    [0.0, 10.0, 0.0],\n",
    "    [0.0, 0.0, 10.0]\n",
    "])\n",
    "\n",
    "# 创建文件夹结构\n",
    "base_folders = [\"./epsilonxx\", \"./epsilonyy\", \"./epsilonzz\", \"./epsilonxy\", \"./epsilonyz\", \"./epsilonzx\"]\n",
    "create_folders(base_folders)\n",
    "\n",
    "# 读取输入文件并生成修改后的文件\n",
    "input_file_path = './C3S_CellOPT.inp'  # 上传的输入文件路径\n",
    "\n",
    "# 遍历每个文件夹并输出修改后的输入文件\n",
    "for folder in base_folders:\n",
    "    # 输出文件路径\n",
    "    pos_file_path = os.path.join(folder, \"pos\", \"displace.inp\")\n",
    "    neg_file_path = os.path.join(folder, \"neg\", \"displace.inp\")\n",
    "    \n",
    "    # 修改输入文件并保存到pos文件夹\n",
    "    modify_cp2k_input(input_file_path, pos_file_path, last_frame_cell_vectors)\n",
    "    # 修改输入文件并保存到neg文件夹\n",
    "    modify_cp2k_input(input_file_path, neg_file_path, last_frame_cell_vectors)\n",
    "\n",
    "# 输出生成的文件路径列表\n",
    "base_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "234aa72f-b03d-4e00-9b0b-9d62362d85dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 复制指定的文件到12个文件夹中的pos和neg子文件夹\n",
    "def copy_files_to_folders(files, base_folders):\n",
    "    for folder in base_folders:\n",
    "        for subfolder in [\"pos\", \"neg\"]:\n",
    "            # 构造目标路径\n",
    "            target_folder = os.path.join(folder, subfolder)\n",
    "            \n",
    "            # 确保目标文件夹存在\n",
    "            if os.path.exists(target_folder):\n",
    "                for file in files:\n",
    "                    # 确保源文件存在\n",
    "                    if os.path.exists(file):\n",
    "                        # 复制文件到目标文件夹\n",
    "                        shutil.copy(file, target_folder)\n",
    "                    else:\n",
    "                        print(f\"Warning: {file} not found. Skipping file.\")\n",
    "            else:\n",
    "                print(f\"Warning: Target folder {target_folder} not found. Skipping.\")\n",
    "\n",
    "# 全局变量：文件路径\n",
    "potential_file = 'POTENTIAL'  # 替换为实际文件名\n",
    "basis_set_file = 'BASIS_MOLOPT'  # 替换为实际文件名\n",
    "dftd3_dat = 'dftd3.dat'           # 替换为实际文件名\n",
    "\n",
    "# 创建文件夹结构\n",
    "base_folders = [\"./epsilonxx\", \"./epsilonyy\", \"./epsilonzz\", \"./epsilonxy\", \"./epsilonyz\", \"./epsilonzx\"]\n",
    "\n",
    "# 文件列表\n",
    "files_to_copy = [potential_file, basis_set_file, dftd3_dat]\n",
    "\n",
    "# 调用函数进行文件复制\n",
    "copy_files_to_folders(files_to_copy, base_folders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3f7accf-745d-4be1-ba31-bebf4485707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shutil\n",
    "from ase import io\n",
    "import subprocess\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "num_cores = 52 \n",
    "cp2k_exec_path = \"/home/zkm/CP2K/cp2k-2024.3/exe/local/cp2k.psmp\" \n",
    "cellopt_inp = \"cellopt.inp\"  \n",
    "cellopt_out = \"cellopt.out\" \n",
    "cellopt_jobname = \"cellopt\"\n",
    "geoopt_inp = \"geoopt.inp\"  \n",
    "geoopt_out = \"geoopt.out\" \n",
    "geoopt_jobname = \"geoopt\"\n",
    "\n",
    "potential_file = 'POTENTIAL'\n",
    "basis_set_file = 'BASIS_MOLOPT'\n",
    "dftd3_dat = 'dftd3.dat'\n",
    "\n",
    "up = 0.01\n",
    "\n",
    "base_folders = [\"./epsilonxx\", \"./epsilonyy\", \"./epsilonzz\", \"./epsilonyz\", \"./epsilonxz\", \"./epsilonxy\"]\n",
    "base_path = Path.cwd()\n",
    "\n",
    "def check_existing_results(cp2k_out, jobname):\n",
    "    if os.path.exists(cp2k_out) and os.path.exists(f\"{jobname}-1.cell\") and os.path.exists(f\"{jobname}-pos-1.xyz\"):\n",
    "        return True\n",
    "    else:\n",
    "        try:\n",
    "            os.remove(cp2k_out)\n",
    "            os.remove(f\"{jobname}-1.cell\")\n",
    "            os.remove(f\"{jobname}-pos-1.xyz\")\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        return False\n",
    "\n",
    "def create_folders(base_folders):\n",
    "    for base_folder in base_folders:\n",
    "        pos_folder = os.path.join(base_folder, \"pos\")\n",
    "        neg_folder = os.path.join(base_folder, \"neg\")\n",
    "        \n",
    "        if os.path.exists(base_folder):\n",
    "            shutil.rmtree(base_folder)\n",
    "        \n",
    "        os.makedirs(pos_folder, exist_ok=True)\n",
    "        os.makedirs(neg_folder, exist_ok=True)\n",
    "\n",
    "def copy_files_to_folders(files, base_folders):\n",
    "    for folder in base_folders:\n",
    "        for subfolder in [\"pos\", \"neg\"]:\n",
    "            target_folder = os.path.join(folder, subfolder)\n",
    "            \n",
    "            if os.path.exists(target_folder):\n",
    "                for file in files:\n",
    "                    if os.path.exists(file):\n",
    "                        shutil.copy(file, target_folder)\n",
    "                    else:\n",
    "                        print(f\"Warning: {file} not found. Skipping file.\")\n",
    "            else:\n",
    "                print(f\"Warning: Target folder {target_folder} not found. Skipping.\")\n",
    "\n",
    "def run_cp2k_optimization(cp2k_inp, cp2k_out, jobname):\n",
    "    if check_existing_results(cp2k_out, jobname):\n",
    "        print(\"This folder already contains the cell optimization results.\")\n",
    "        return\n",
    "        \n",
    "    command = [\n",
    "        \"mpirun\", \n",
    "        \"-n\", str(num_cores), \n",
    "        cp2k_exec_path, \n",
    "        \"-o\", cp2k_out, \n",
    "        cp2k_inp\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        print(f\"Running CP2K with {num_cores} cores...\")\n",
    "        result = subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        \n",
    "        print(f\"CP2K run completed successfully. Output is saved to {cp2k_out}.\")\n",
    "        print(\"Standard Output:\", result.stdout.decode())\n",
    "        print(\"Standard Error:\", result.stderr.decode())\n",
    "    \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error occurred during CP2K execution: {e}\")\n",
    "        print(\"Standard Output:\", e.stdout.decode())\n",
    "        print(\"Standard Error:\", e.stderr.decode())\n",
    "\n",
    "def extract_last_frame(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        file_content = file.readlines()\n",
    "\n",
    "    frame_start_index = None\n",
    "    for i in range(len(file_content) - 1, -1, -1):\n",
    "        if file_content[i].startswith(\" i =\"):\n",
    "            frame_start_index = i\n",
    "            break\n",
    "\n",
    "    atoms_in_last_frame = file_content[frame_start_index + 1:]\n",
    "\n",
    "    frame_end_index = None\n",
    "    for i in range(len(atoms_in_last_frame)):\n",
    "        if atoms_in_last_frame[i].startswith(\" i =\"):\n",
    "            frame_end_index = i\n",
    "            break\n",
    "            \n",
    "    if frame_end_index is not None:\n",
    "        atoms_in_last_frame = atoms_in_last_frame[:frame_end_index]\n",
    "\n",
    "    atom_data = []\n",
    "    for line in atoms_in_last_frame:\n",
    "        atom_info = line.split()\n",
    "        atom_name = atom_info[0]\n",
    "        coordinates = [float(coord) for coord in atom_info[1:]]\n",
    "        atom_data.append((atom_name, coordinates))\n",
    "    return atom_data\n",
    "\n",
    "def read_last_frame_cell_vectors(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = [line for line in file.readlines() if line.strip()]\n",
    "\n",
    "    last_frame_line = content[-1]\n",
    "    parts = last_frame_line.split()\n",
    "\n",
    "    vector_a = [np.round(float(parts[2]), 10), np.round(float(parts[3]), 10), np.round(float(parts[4]), 10)]\n",
    "    vector_b = [np.round(float(parts[5]), 10), np.round(float(parts[6]), 10), np.round(float(parts[7]), 10)]\n",
    "    vector_c = [np.round(float(parts[8]), 10), np.round(float(parts[9]), 10), np.round(float(parts[10]), 10)]\n",
    "\n",
    "    cell_vectors = np.array([vector_a, vector_b, vector_c])\n",
    "    return cell_vectors\n",
    "\n",
    "def save_xyz_file(atom_data, cell_vectors, output_path):\n",
    "    num_atoms = len(atom_data)\n",
    "    with open(output_path, 'w') as file:\n",
    "        file.write(f\"{num_atoms}\\n\")\n",
    "        file.write(f'Lattice=\"{\" \".join(map(str, cell_vectors.flatten()))}\" Properties=species:S:1:pos:R:3 pbc=\"T T T\"\\n')\n",
    "        \n",
    "        for atom in atom_data:\n",
    "            atom_name = atom[0]\n",
    "            coordinates = atom[1]\n",
    "            formatted_coords = \" \".join([f\"{coord:.10f}\" for coord in coordinates])\n",
    "            file.write(f\"{atom_name} {formatted_coords}\\n\")\n",
    "\n",
    "def extract_last_stress_tensor(file_path):\n",
    "    \n",
    "    stress_tensors = []\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "        # 遍历文件中的每一行\n",
    "        for i, line in enumerate(lines):\n",
    "            if 'STRESS| Analytical stress tensor [GPa]' in line:\n",
    "                # 找到 STRESS| Analytical stress tensor 的位置，开始解析应力矩阵\n",
    "                stress_matrix = []\n",
    "                for j in range(i + 2, i + 5):  # 取接下来的 3 行应力张量\n",
    "                    row_data = lines[j].split()[2:]  # 取 x, y, z 列的值\n",
    "                    stress_matrix.append([np.round(float(val), 11) for val in row_data])\n",
    "                stress_tensors.append(np.array(stress_matrix))  # 将该矩阵加入到列表中\n",
    "    if stress_tensors:\n",
    "        return stress_tensors[-1]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def modify_cp2k_input(input_file_path, output_file_path, cell_vectors):\n",
    "    with open(input_file_path, 'r') as file:\n",
    "        input_lines = file.readlines()\n",
    "\n",
    "    # 标志位，判断是否进入&CELL部分\n",
    "    in_cell_section = False\n",
    "    new_lines = []\n",
    "\n",
    "    # 记录&CELL部分的缩进\n",
    "    cell_indent = None\n",
    "\n",
    "    for line in input_lines:\n",
    "        # 检查是否进入&CELL部分\n",
    "        if \"&CELL\" in line:\n",
    "            in_cell_section = True\n",
    "            cell_indent = len(line) - len(line.lstrip())  # 获取&CELL行的前导空格数\n",
    "            new_lines.append(line)  # 保留原有的&CELL部分头\n",
    "            continue\n",
    "\n",
    "        # 如果进入了&CELL部分，并且当前行是A、B、C基础矢量行，进行修改\n",
    "        if in_cell_section:\n",
    "            if \"&END CELL\" in line:\n",
    "                in_cell_section = False\n",
    "                new_lines.append(line)\n",
    "            else:\n",
    "                # 忽略每行前的空格，检查是否是A、B、C行\n",
    "                stripped_line = line.strip()\n",
    "                if stripped_line.startswith(\"A\"):\n",
    "                    new_lines.append(f\"{' ' * (cell_indent + 2)}A  {cell_vectors[0,0]:.10f} {cell_vectors[0,1]:.10f} {cell_vectors[0,2]:.10f}\\n\")\n",
    "                elif stripped_line.startswith(\"B\"):\n",
    "                    new_lines.append(f\"{' ' * (cell_indent + 2)}B  {cell_vectors[1,0]:.10f} {cell_vectors[1,1]:.10f} {cell_vectors[1,2]:.10f}\\n\")\n",
    "                elif stripped_line.startswith(\"C\"):\n",
    "                    new_lines.append(f\"{' ' * (cell_indent + 2)}C  {cell_vectors[2,0]:.10f} {cell_vectors[2,1]:.10f} {cell_vectors[2,2]:.10f}\\n\")\n",
    "                else:\n",
    "                    new_lines.append(line)\n",
    "        else:\n",
    "            new_lines.append(line)\n",
    "\n",
    "    # 将修改后的内容写入到新的输入文件\n",
    "    with open(output_file_path, 'w') as output_file:\n",
    "        output_file.writelines(new_lines)\n",
    "\n",
    "epsilon_values = {\n",
    "    \"./epsilonxx\": np.array([[up, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0]]),\n",
    "    \"./epsilonyy\": np.array([[0.0, 0.0, 0.0], [0.0, up, 0.0], [0.0, 0.0, 0.0]]),\n",
    "    \"./epsilonzz\": np.array([[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, up]]),\n",
    "    \"./epsilonyz\": np.array([[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, up, 0.0]]),\n",
    "    \"./epsilonxz\": np.array([[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [up, 0.0, 0.0]]),\n",
    "    \"./epsilonxy\": np.array([[0.0, 0.0, 0.0], [up, 0.0, 0.0], [0.0, 0.0, 0.0]]),\n",
    "}\n",
    "\n",
    "def process_epsilon(folder, epsilon, cell_vectors_cellopt, input_file_path):\n",
    "    cell_vectors_disp_pos = np.round(np.dot(cell_vectors_cellopt, (np.eye(3) + epsilon)), 10)\n",
    "    cell_vectors_disp_neg = np.round(np.dot(cell_vectors_cellopt, (np.eye(3) - epsilon)), 10)\n",
    "    \n",
    "    pos_file_path = os.path.join(folder, \"pos\", geoopt_inp)\n",
    "    neg_file_path = os.path.join(folder, \"neg\", geoopt_inp)\n",
    "    \n",
    "    modify_cp2k_input(input_file_path, pos_file_path, cell_vectors_disp_pos)\n",
    "    modify_cp2k_input(input_file_path, neg_file_path, cell_vectors_disp_neg)\n",
    "\n",
    "    output_xyz_pos = os.path.join(folder, \"pos\", \"coord.xyz\")\n",
    "    output_xyz_neg = os.path.join(folder, \"neg\", \"coord.xyz\")\n",
    "    remap_xyz(cell_vectors_disp_pos, \"./coord_cellopt.xyz\", output_xyz_pos)\n",
    "    remap_xyz(cell_vectors_disp_neg, \"./coord_cellopt.xyz\", output_xyz_neg)\n",
    "\n",
    "def remap_xyz(cell_vectors, coord_file, output_file):\n",
    "    atoms = io.read(coord_file)\n",
    "    atoms.set_cell(cell_vectors, scale_atoms=False)\n",
    "    atoms.wrap()\n",
    "    atoms.positions = np.round(atoms.positions, 10)\n",
    "    atoms.write(output_file)\n",
    "\n",
    "def symmetrize_and_save(array, filename=\"Cij.dat\"):\n",
    "    if array.ndim != 2 or array.shape[0] != array.shape[1]:\n",
    "        raise ValueError(\"Cij have to be a (2D square array)!\")\n",
    "    symm_array = (array + array.T) / 2\n",
    "    np.fill_diagonal(symm_array, np.diag(array))\n",
    "    np.savetxt(filename, symm_array, fmt='%.3f')\n",
    "    return symm_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0456ace0-6071-43ea-8671-181801974f77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.22716146 -0.02974587 -0.02476658]\n",
      " [-0.02974587 -0.62443084 -0.00548213]\n",
      " [-0.02476658 -0.00548213 -0.47545665]]\n",
      "123.012959552\n",
      "[[ 1.05177182  0.09406071 -0.05785465]\n",
      " [ 0.09406071  0.21166508  0.03805441]\n",
      " [-0.05785465  0.03805441  0.34118594]]\n",
      "104.88036837099999\n",
      "[[113.947   0.      0.      0.      0.      0.   ]\n",
      " [ 41.805   0.      0.      0.      0.      0.   ]\n",
      " [ 40.832   0.      0.      0.      0.      0.   ]\n",
      " [  2.177   0.      0.      0.      0.      0.   ]\n",
      " [ -1.654   0.      0.      0.      0.      0.   ]\n",
      " [  6.19    0.      0.      0.      0.      0.   ]]\n",
      "[[-0.47699409  0.13927254  0.02830674]\n",
      " [ 0.13927254 -1.43247024  0.00441173]\n",
      " [ 0.02830674  0.00441173 -0.50778097]]\n",
      "47.996222406\n",
      "[[ 0.35119438 -0.0278565  -0.11891954]\n",
      " [-0.0278565   1.06410149  0.04611529]\n",
      " [-0.11891954  0.04611529  0.36687405]]\n",
      "34.822623966\n",
      "[[113.947  41.409   0.      0.      0.      0.   ]\n",
      " [ 41.805 124.829   0.      0.      0.      0.   ]\n",
      " [ 40.832  43.733   0.      0.      0.      0.   ]\n",
      " [  2.177   2.085   0.      0.      0.      0.   ]\n",
      " [ -1.654  -7.361   0.      0.      0.      0.   ]\n",
      " [  6.19   -8.356   0.      0.      0.      0.   ]]\n",
      "[[-0.39243824  0.0300792  -0.05415218]\n",
      " [ 0.0300792  -0.53189557  0.10472221]\n",
      " [-0.05415218  0.10472221 -0.5596053 ]]\n",
      "39.540637509\n",
      "[[ 0.29263163  0.00753742 -0.00953625]\n",
      " [ 0.00753742  0.26402241 -0.0994384 ]\n",
      " [-0.00953625 -0.0994384   0.78231961]]\n",
      "28.966349079999997\n",
      "[[113.947  41.409  34.253   0.      0.      0.   ]\n",
      " [ 41.805 124.829  39.796   0.      0.      0.   ]\n",
      " [ 40.832  43.733  67.096   0.      0.      0.   ]\n",
      " [  2.177   2.085 -10.208   0.      0.      0.   ]\n",
      " [ -1.654  -7.361   2.231   0.      0.      0.   ]\n",
      " [  6.19   -8.356  -1.127   0.      0.      0.   ]]\n",
      "[[-0.13316775  0.11368955 -0.00600882]\n",
      " [ 0.11368955 -0.33568171 -0.26341036]\n",
      " [-0.00600882 -0.26341036 -0.1909907 ]]\n",
      "13.613588906999999\n",
      "[[ 0.00227105 -0.02923516  0.03048855]\n",
      " [-0.02923516 -0.12263644  0.23705499]\n",
      " [ 0.03048855  0.23705499 -0.05278006]]\n",
      "-0.069708426\n",
      "[[113.947  41.409  34.253   6.772   0.      0.   ]\n",
      " [ 41.805 124.829  39.796  10.652   0.      0.   ]\n",
      " [ 40.832  43.733  67.096   6.911   0.      0.   ]\n",
      " [  2.177   2.085 -10.208  25.023   0.      0.   ]\n",
      " [ -1.654  -7.361   2.231   1.825   0.      0.   ]\n",
      " [  6.19   -8.356  -1.127  -7.146   0.      0.   ]]\n",
      "[[-0.10720913  0.00812166 -0.10179548]\n",
      " [ 0.00812166  0.00692602 -0.08469506]\n",
      " [-0.10179548 -0.08469506  0.04083152]]\n",
      "11.017726839\n",
      "[[ 0.00383664  0.05649449  0.22525511]\n",
      " [ 0.05649449 -0.24032207 -0.0778062 ]\n",
      " [ 0.22525511 -0.0778062  -0.02023881]]\n",
      "0.08685036499999996\n",
      "[[113.947  41.409  34.253   6.772   5.552   0.   ]\n",
      " [ 41.805 124.829  39.796  10.652 -12.362   0.   ]\n",
      " [ 40.832  43.733  67.096   6.911  -3.054   0.   ]\n",
      " [  2.177   2.085 -10.208  25.023   0.344   0.   ]\n",
      " [ -1.654  -7.361   2.231   1.825  16.353   0.   ]\n",
      " [  6.19   -8.356  -1.127  -7.146   2.419   0.   ]]\n",
      "[[-0.12460007 -0.37934789 -0.08284508]\n",
      " [-0.37934789  0.00965062  0.06696407]\n",
      " [-0.08284508  0.06696407  0.00861511]]\n",
      "12.756820991\n",
      "[[-0.03287066  0.36630064  0.01612369]\n",
      " [ 0.36630064 -0.15732978 -0.09656853]\n",
      " [ 0.01612369 -0.09656853 -0.04383357]]\n",
      "-3.5838794310000006\n",
      "[[113.947  41.409  34.253   6.772   5.552   4.586]\n",
      " [ 41.805 124.829  39.796  10.652 -12.362  -8.349]\n",
      " [ 40.832  43.733  67.096   6.911  -3.054  -2.622]\n",
      " [  2.177   2.085 -10.208  25.023   0.344  -8.177]\n",
      " [ -1.654  -7.361   2.231   1.825  16.353   4.948]\n",
      " [  6.19   -8.356  -1.127  -7.146   2.419  37.282]]\n"
     ]
    }
   ],
   "source": [
    "Cij = np.zeros((6, 6))\n",
    "cellopt_inp = \"cellopt.inp\"  \n",
    "cellopt_out = \"cellopt.out\" \n",
    "cellopt_jobname = \"cellopt\"\n",
    "geoopt_inp = \"geoopt.inp\"  \n",
    "geoopt_out = \"geoopt.out\" \n",
    "geoopt_jobname = \"geoopt\"\n",
    "up = 0.01\n",
    "\n",
    "for index, folder in enumerate(base_folders):\n",
    "    os.chdir(base_path)\n",
    "    stress_tensor_cellopt = extract_last_stress_tensor(cellopt_out)\n",
    "    \n",
    "    os.chdir(os.path.join(base_path, folder, \"pos\"))\n",
    "    stress_tensor = extract_last_stress_tensor(geoopt_out)\n",
    "    print(stress_tensor)\n",
    "    Cn1_pos = - (stress_tensor[0,0] - stress_tensor_cellopt[0,0]) / (up)\n",
    "    Cn2_pos = - (stress_tensor[1,1] - stress_tensor_cellopt[1,1]) / (up)\n",
    "    Cn3_pos = - (stress_tensor[2,2] - stress_tensor_cellopt[2,2]) / (up)\n",
    "    Cn4_pos = - (stress_tensor[1,2] - stress_tensor_cellopt[1,2]) / (up) #yz\n",
    "    Cn5_pos = - (stress_tensor[0,2] - stress_tensor_cellopt[0,2]) / (up) #xz\n",
    "    Cn6_pos = - (stress_tensor[0,1] - stress_tensor_cellopt[0,1]) / (up) #xy\n",
    "    print(Cn1_pos)\n",
    "    \n",
    "    os.chdir(os.path.join(base_path, folder, \"neg\"))\n",
    "    stress_tensor = extract_last_stress_tensor(geoopt_out)\n",
    "    print(stress_tensor)\n",
    "    Cn1_neg = (stress_tensor[0,0] - stress_tensor_cellopt[0,0]) / (up)\n",
    "    Cn2_neg = (stress_tensor[1,1] - stress_tensor_cellopt[1,1]) / (up)\n",
    "    Cn3_neg = (stress_tensor[2,2] - stress_tensor_cellopt[2,2]) / (up)\n",
    "    Cn4_neg = (stress_tensor[1,2] - stress_tensor_cellopt[1,2]) / (up) #yz\n",
    "    Cn5_neg = (stress_tensor[0,2] - stress_tensor_cellopt[0,2]) / (up) #xz\n",
    "    Cn6_neg = (stress_tensor[0,1] - stress_tensor_cellopt[0,1]) / (up) #xy\n",
    "    print(Cn1_neg)\n",
    "\n",
    "    Cn1 =  np.round((Cn1_pos + Cn1_neg) / 2, 3)\n",
    "    Cn2 =  np.round((Cn2_pos + Cn2_neg) / 2, 3)\n",
    "    Cn3 =  np.round((Cn3_pos + Cn3_neg) / 2, 3)\n",
    "    Cn4 =  np.round((Cn4_pos + Cn4_neg) / 2, 3)\n",
    "    Cn5 =  np.round((Cn5_pos + Cn5_neg) / 2, 3)\n",
    "    Cn6 =  np.round((Cn6_pos + Cn6_neg) / 2, 3)\n",
    "    Cij[:, index] = [Cn1, Cn2, Cn3, Cn4, Cn5, Cn6]\n",
    "    print(Cij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ed5f9af-8db3-45ba-8d9c-4aed1c6c489f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ./epsilonxy\n",
      "1 ./epsilonxy\n",
      "2 ./epsilonxy\n",
      "3 ./epsilonxy\n",
      "4 ./epsilonxy\n",
      "5 ./epsilonxy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "Cij = np.zeros((6, 6))\n",
    "new_values = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# 向第 2 列（索引为 1）添加值\n",
    "Cij[:, 0] = new_values\n",
    "Cij\n",
    "base_folders = [\"./epsilonxx\", \"./epsilonyy\", \"./epsilonzz\", \"./epsilonyz\", \"./epsilonxz\", \"./epsilonxy\"]\n",
    "for index, folder in enumerate(base_folders):\n",
    "    print(index, folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "07c1ce73-3ac1-4690-9ad9-f263b57227dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数组:\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "\n",
      "对称化后的数组:\n",
      "[[1. 3. 5.]\n",
      " [4. 5. 7.]\n",
      " [7. 8. 9.]]\n",
      "1 2 3\n",
      "4 5 6\n",
      "7 8 9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 示例：创建一个非对称的 3x3 数组\n",
    "array = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "])\n",
    "\n",
    "# 提取上三角部分（不包括对角线）\n",
    "upper_triangle = np.triu(array, k=1)\n",
    "\n",
    "# 提取下三角部分（不包括对角线）\n",
    "lower_triangle = np.tril(array, k=-1)\n",
    "\n",
    "# 对称化：将上三角和下三角部分相加并取平均值\n",
    "symmetric_array = (upper_triangle + lower_triangle.T) / 2\n",
    "\n",
    "# 将对称化后的部分加回原始数组\n",
    "symmetric_array += np.tril(array, k=0)  # 保持下三角和对角线不变\n",
    "\n",
    "\n",
    "print(\"原始数组:\")\n",
    "print(array)\n",
    "print(\"\\n对称化后的数组:\")\n",
    "print(symmetric_array)\n",
    "\n",
    "df = pd.DataFrame(array)\n",
    "print(df.to_string(index=False, header=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b7e3571e-bba6-4eff-92b4-3c6c696b308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "array = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "])\n",
    "os.chdir(base_path)\n",
    "def symmetrize_and_save(array, filename=\"Cij.dat\"):\n",
    "    if array.ndim != 2 or array.shape[0] != array.shape[1]:\n",
    "        raise ValueError(\"Cij have to be a (2D square array)!\")\n",
    "    symm_array = (array + array.T) / 2\n",
    "    np.fill_diagonal(symm_array, np.diag(array))\n",
    "    np.savetxt(filename, symm_array, fmt='%.3f')\n",
    "symmetrize_and_save(array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
